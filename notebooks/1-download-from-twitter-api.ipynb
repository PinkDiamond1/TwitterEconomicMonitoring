{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2262nmEeEbgH"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1uId6X7aAQupJMnEOt1xhQ80PpGnOx_NQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qOF1EDjDEbgL"
   },
   "source": [
    "# Notebook #1: tweet extraction from the Twitter API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ckxmB5hEbgM"
   },
   "source": [
    "## Description and requirements: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JsdBhwRREbgN"
   },
   "source": [
    "In this notebook, you will learn how to extract tweets and information about Twitter users from the Twitter API in Python. \n",
    "\n",
    "A requirement for this code to work is to have Twitter API keys and access tokens. The steps to request the latter are described in [this tutorial](https://www.slickremix.com/docs/how-to-get-api-keys-and-tokens-for-twitter/). \n",
    "\n",
    "Also, on top of the usual Python modules (numpy and pandas), you will need to install the [tweepy](http://docs.tweepy.org/en/latest/index.html) package. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lyJFfG1jEbgP"
   },
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i1JEv-K4EbgR"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import uuid\n",
    "\n",
    "import pandas as pd\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RN35sJp7EbgR"
   },
   "source": [
    "### Process credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7w11dUX5EbgS"
   },
   "source": [
    "Before we start, please replace the placeholders below by your API credentials. Make sure to keep them private and remove them before sharing this notebook with third-parties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rWs_mwz-EbgS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "api_dict = {\"API Key\": \"Enter your own API Key\",\n",
    "            \"API Secret Key\": \"Enter your own API Secret Key\",\n",
    "            \"Bearer token\": \"Enter your own Bearer token\",\n",
    "            \"access_token\": \"Enter your own access_token\",\n",
    "            \"access_token_secret\": \"Enter your own access_token_secret\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IAqjy_bpEbgT"
   },
   "source": [
    "Now that you have informed your credentials, we will check whether the API recognizes them as valid credentials. The function below will do this and return an error if this is not the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PLriK2zvEbgU"
   },
   "outputs": [],
   "source": [
    "def get_auth(api_dict):\n",
    "    # OAuth process, using the keys and tokens\n",
    "    auth = tweepy.OAuthHandler(api_dict['API Key'], api_dict['API Secret Key'])\n",
    "    auth.set_access_token(api_dict['access_token'], api_dict['access_token_secret'])\n",
    "\n",
    "    # Creation of the actual interface, using authentication\n",
    "    api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "\n",
    "    try:\n",
    "        api.verify_credentials()\n",
    "    except:\n",
    "        print(api_dict, \": error during authentication\")\n",
    "        sys.exit('Exit')\n",
    "    return api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VtVk2nM0EbgU",
    "outputId": "48405f42-306d-41eb-a7a6-d663eb317b10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credentials Checked!\n"
     ]
    }
   ],
   "source": [
    "get_auth(api_dict)\n",
    "print('Credentials Checked!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CpAWlvtrEbgV"
   },
   "source": [
    "### Downloading tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0psf4XHEbgV"
   },
   "source": [
    "The Twitter API allows developers to download several types of information on the social network and its users. In this section, we will focus on three types of Twitter data:\n",
    "- tweets by hashtag\n",
    "- tweets by user\n",
    "- list of users that a given user follows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cO1MQm9iEbgW"
   },
   "source": [
    "Before we go on, please note that each developer is limited in the amount of requests she can make to the Twitter API. This is important to take into account if you want to download an important number of tweets. You will find more information on the API rate limit in the [FAQ](https://developer.twitter.com/en/docs/twitter-api/v1/tweets/timelines/faq) of the Twitter Developer documentation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3J-BxO3oEbgW"
   },
   "source": [
    "#### By hashtag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZPaCbrcEbgW"
   },
   "source": [
    "First, tweets can be selected on the basis of hashtags. This can be relevant if you want to study the importance of specific topics in the Twitter-verse and what users have to say about these topics.\n",
    "\n",
    "The function below takes as input:\n",
    "- the `api_dict` dictionary, containing our credentials and defined earlier\n",
    "- a list of hashtags `tags_list`\n",
    "- `language` the language of the tweet\n",
    "- `count_int` the number of tweets to download per hashtag\n",
    "\n",
    "It then loops over the list of hashtags `tags_list`, downloads `count_int` tweets per hashtag and return tweets and related information in a Pandas dataframe format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tTRDEeNCEbgW",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_tags(api_dict, tags_list, language, count_int):\n",
    "    # Create Access For Block of Users\n",
    "    api = get_auth(api_dict)\n",
    "\n",
    "    tweets = []\n",
    "    for tag in tags_list:\n",
    "        try:\n",
    "            cursor = tweepy.Cursor(\n",
    "                api.search,\n",
    "                q=f'#{tag}',\n",
    "                language=language).items(count_int)\n",
    "            for tweet in cursor:\n",
    "                tweets.append(tweet)\n",
    "        except tweepy.error.TweepError as e:\n",
    "            print(e)\n",
    "            continue\n",
    "    print(f'Got {len(tweets)} Tweets!!')\n",
    "    tweets = [tweet._json for tweet in tweets]\n",
    "    return pd.DataFrame(data=tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8HnCVDI_EbgX"
   },
   "source": [
    "Let's look at an example. Say we want to download 10 tweets with the hashtag #COVID-19. We can do this in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-jHEEuTNEbgX",
    "outputId": "3a0e84fd-eb7e-40f4-81e2-70ffe9469503"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 10 Tweets!!\n"
     ]
    }
   ],
   "source": [
    "covid19_tweets_df = get_tags(api_dict=api_dict, tags_list=['COVID19'], language='en', count_int=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Su2o_gF-EbgY"
   },
   "source": [
    "The output dataframe has 10 rows (one tweet per row) and 28 columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VKgboaLjEbgY",
    "outputId": "6a33720a-a521-4163-e583-6b5c83f9c1f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 27)"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid19_tweets_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uSRpwkXxEbgY"
   },
   "source": [
    "These 28 columns listed below give a lot of details on the tweets, including the date of creation, the tweet ID and the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TjptjubREbgY",
    "outputId": "1b00c798-f502-4526-997f-0651c083d8c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['created_at', 'id', 'id_str', 'text', 'truncated', 'entities',\n",
       "       'metadata', 'source', 'in_reply_to_status_id',\n",
       "       'in_reply_to_status_id_str', 'in_reply_to_user_id',\n",
       "       'in_reply_to_user_id_str', 'in_reply_to_screen_name', 'user', 'geo',\n",
       "       'coordinates', 'place', 'contributors', 'retweeted_status',\n",
       "       'is_quote_status', 'retweet_count', 'favorite_count', 'favorited',\n",
       "       'retweeted', 'lang', 'possibly_sensitive', 'extended_entities'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid19_tweets_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IwvQ6idEEbgZ"
   },
   "source": [
    "If we focus on the text, here are the first 5 tweets we picked up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xk4tmx9KEbga",
    "outputId": "9e32e458-1532-4440-d155-d3d4d0753d38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    RT @PetroDivisa: Carlos Holmes Trujillo un col...\n",
       "1    RT @tim_fargo: “When one door of happiness clo...\n",
       "2    RT @VilledAjaccio: #COVID19\\nℹ Vous êtes comme...\n",
       "3    RT @enricomolinari: How #COVID19 hit Europe #s...\n",
       "4    RT @FBIDallas: Have you received a call, text,...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid19_tweets_df['text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lXRV8otREbgb"
   },
   "source": [
    "#### By user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FzIK5TfzEbgb"
   },
   "source": [
    "Another option when downloading tweets is to download the tweets from one or several specific users. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fIXPFYavEbgb"
   },
   "source": [
    "The function below takes as input:\n",
    "- `screen_name` the screen name of a Twitter user (another name for a Twitter handle)\n",
    "- `api` the authenticated API credentials\n",
    "\n",
    "It returns a tuple containing the timeline of that Twitter user in a Pandas dataframe format and, the error message from Tweepy in case there is one. The upper bound of the number of tweets to download is set to 3200 (`count` argument) to avoid API rate limit errors. We also choose the extended `tweet_mode` to avoid the truncating of tweets the Tweepy tool does by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vax2U6vJEbgb"
   },
   "outputs": [],
   "source": [
    "def get_timeline(screen_name, api):\n",
    "    timeline = []\n",
    "    error = None\n",
    "    # Collect All Statuses in Timeline\n",
    "    try:\n",
    "        cursor = tweepy.Cursor(\n",
    "            api.user_timeline,\n",
    "            screen_name=screen_name,\n",
    "            tweet_mode=\"extended\",\n",
    "            count=3200,\n",
    "            include_rts=False).items()\n",
    "\n",
    "        for status in cursor:\n",
    "            timeline.append(status._json)\n",
    "    except tweepy.error.TweepError as e:\n",
    "        error = str(e)\n",
    "    return pd.DataFrame(timeline), error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example with Joe Biden's timeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HmdYae9ZEbgc"
   },
   "source": [
    "As an example, let's download Joe Biden's timeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "id": "Itf3AT0MEbgc",
    "outputId": "f9b39d79-baf1-40c6-97ec-89e37ba5bfe6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>full_text</th>\n",
       "      <th>truncated</th>\n",
       "      <th>display_text_range</th>\n",
       "      <th>entities</th>\n",
       "      <th>extended_entities</th>\n",
       "      <th>source</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_status_id_str</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>in_reply_to_user_id_str</th>\n",
       "      <th>in_reply_to_screen_name</th>\n",
       "      <th>user</th>\n",
       "      <th>geo</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>place</th>\n",
       "      <th>contributors</th>\n",
       "      <th>is_quote_status</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>favorited</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>lang</th>\n",
       "      <th>quoted_status_id</th>\n",
       "      <th>quoted_status_id_str</th>\n",
       "      <th>quoted_status_permalink</th>\n",
       "      <th>quoted_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wed Jan 20 17:55:22 +0000 2021</td>\n",
       "      <td>1351951465674276869</td>\n",
       "      <td>1351951465674276869</td>\n",
       "      <td>Now the real work begins, folks. Follow along ...</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 80]</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>{'media': [{'id': 1351951461567979525, 'id_str...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'id': 939091, 'id_str': '939091', 'name': 'Jo...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>63919</td>\n",
       "      <td>897967</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at  ...  quoted_status\n",
       "0  Wed Jan 20 17:55:22 +0000 2021  ...            NaN\n",
       "\n",
       "[1 rows x 30 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joe_biden_timeline_df = get_timeline(screen_name='JoeBiden', api=get_auth(api_dict))[0]\n",
    "joe_biden_timeline_df.head(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qk35k1ROEbgc"
   },
   "source": [
    "We have successfully downloaded 3003 tweets (one tweet per row) from Joe Biden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gMynYuftEbgd",
    "outputId": "510cb6bb-bfc5-47d7-985c-c790d2229551"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3003, 30)"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joe_biden_timeline_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cRmM9KNBEbgd"
   },
   "source": [
    "The dataframe contains 30 columns with specific information on each tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9MRMi-8XEbgd",
    "outputId": "0c1adeca-9639-4dd4-b6fb-109a58203d10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['created_at', 'id', 'id_str', 'full_text', 'truncated',\n",
       "       'display_text_range', 'entities', 'extended_entities', 'source',\n",
       "       'in_reply_to_status_id', 'in_reply_to_status_id_str',\n",
       "       'in_reply_to_user_id', 'in_reply_to_user_id_str',\n",
       "       'in_reply_to_screen_name', 'user', 'geo', 'coordinates', 'place',\n",
       "       'contributors', 'is_quote_status', 'retweet_count', 'favorite_count',\n",
       "       'favorited', 'retweeted', 'possibly_sensitive', 'lang',\n",
       "       'quoted_status_id', 'quoted_status_id_str', 'quoted_status_permalink',\n",
       "       'quoted_status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joe_biden_timeline_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example with Imran Khan's timeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDEn5vJNEbge",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We will now download tweets from Pakistani Twitter users. To do so, we will first grab a list of 300 followers from Imran Khan, the current Prime Minister of Pakistan. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I5vvQ8IFEbge",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In order to achieve this, we will define the following function:\n",
    "\n",
    "The function below takes as input:\n",
    "- `user_names` a list of screen names whose user_ids we want\n",
    "- `amount` the amount of users we wish to obtain\n",
    "\n",
    "It then returns a list of `followers`, containing `amount` followers for each user in the `user_names` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZYGXbqYDEbge",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_followers(user_names, amount):\n",
    "    api = get_auth(api_dict)\n",
    "    followers = []\n",
    "    for user_name in user_names:\n",
    "        try:\n",
    "            for follower in tweepy.Cursor(api.followers, user_name).items(amount):\n",
    "                followers.extend([follower.screen_name])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            break\n",
    "    print(f'Got {len(followers)} followers!!')\n",
    "    return followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mEDgmT8AEbgf",
    "outputId": "74886fc7-607b-42ba-ecd4-06b2d599dd7c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 100 followers!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RabbyAh36419387',\n",
       " 'MHafeezBuzdar3',\n",
       " 'AmirShe06581205',\n",
       " 'imrulka86583184',\n",
       " 'AbubakarRindh',\n",
       " 'Rijanoor5',\n",
       " 'Noorfatima9695',\n",
       " 'Attia97838963',\n",
       " 'Mohamma85924197',\n",
       " 'IrumKha08419063']"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_names = ['ImranKhanPTI']\n",
    "followers_screen_names = get_followers(user_names, 100)\n",
    "# print 10 first users\n",
    "followers_screen_names[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nYGYwiSQEbgf"
   },
   "source": [
    "When wanting to draw policy insights from tweets, one timeline is usually not enough. We will now show how to download and save the timelines of several users. We first define an output path `path_to_timelines` where the timelines will be saved. Please modify it with a local path on your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ReyYQ7WVEbgf"
   },
   "outputs": [],
   "source": [
    "path_to_timelines = './data/timelines'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XVgBN30OEbgf"
   },
   "source": [
    "Next we would like to save the downloaded timelines. Inorder to do this we will create a function that will receive timelines and will save it to a location.\n",
    "The function below takes an input:\n",
    "- `downloaded_screen_name_list` a list of screen names whose timelines were downloaded\n",
    "- `output_id` an ID to differentiate different outputs\n",
    "- `user_index` the rank of the user screen name in the list of screen names to download\n",
    "- `timelines` the tweet data in pandas dataframe format\n",
    "\n",
    "It then saves the dataframe in the `path_to_timelines` folder in a pickle format. The file name is defined as: `timelines-NB_DOWNLOADED_TIMELINES-OUTPUT_ID.pkl` where `NB_DOWNLOADED_TIMELINES` is the number of downloaded timelines and `OUTPUT_ID` is a randomly generated ID. A `success` text file is also saved and informs on the filename where the timeline of a specific user is saved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8xUxyXBAEbgf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def save_timelines(downloaded_screen_name_list, output_id, user_index, timelines):\n",
    "    filename = 'timelines-' + str(len(downloaded_screen_name_list)) + '-' + output_id + '.pkl'\n",
    "\n",
    "    print('Process', 'processed', str(int(user_index) + 1 ), 'timelines with latest output file:',\n",
    "          os.path.join(path_to_timelines, filename))\n",
    "    dir_path = os.path.join(path_to_timelines)\n",
    "    # Save as list of dict discarding index\n",
    "    timelines.to_pickle(os.path.join(dir_path, filename))\n",
    "\n",
    "    # Save User Id and File In Which Its Timeline Was Saved\n",
    "    with open(os.path.join(path_to_timelines, 'success'), 'a', encoding='utf-8') as file:\n",
    "        for downloaded_screen_name in downloaded_screen_name_list:\n",
    "            file.write(f'{downloaded_screen_name}\\t{filename}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mLiEbtiNEbgf"
   },
   "source": [
    "We define a `cutoff` variable which works in the following manner: when the number of downloaded timelines reaches `cutoff`, these timelines are saved and then deleted from memory. The idea is to avoid losing already downloaded data in case of an error from the Tweepy client. Here, we define `cutoff` as equal to 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e7is79jIEbgg"
   },
   "outputs": [],
   "source": [
    "cutoff = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8MzBYo5pEbgg"
   },
   "source": [
    "The function below combines the functions `get_timeline` and `save_timelines`. It takes as input:\n",
    "- `api_dict` the API credentials in a dictionary format\n",
    "- `screen_name_list` a list of users screen names\n",
    "\n",
    "It then downloads the timelines of each of the users in `screen_name_list` and saves these timelines in the `path_to_timelines` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yhJaFYqYEbgg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def download_timelines(api_dict, screen_name_list):\n",
    "    # Create Access For Block of Users\n",
    "    api = get_auth(api_dict)\n",
    "    # Initialize Output File ID\n",
    "    output_id = str(uuid.uuid4())\n",
    "    # Initialize DataFrame\n",
    "    timelines = pd.DataFrame()\n",
    "    # Initialize Downloaded User List\n",
    "    downloaded_screen_name_list = []\n",
    "    for user_index, screen_name in enumerate(screen_name_list):\n",
    "        # Try Downloading Timeline\n",
    "        timeline, error = get_timeline(screen_name, api)\n",
    "        if error is not None:\n",
    "            print(screen_name, error)\n",
    "            continue\n",
    "        # Append\n",
    "        timelines = pd.concat([timelines, timeline], sort=False)\n",
    "        downloaded_screen_name_list.append(screen_name)\n",
    "        # Save after <cutoff> timelines\n",
    "        if len(downloaded_screen_name_list) == cutoff:\n",
    "            save_timelines(downloaded_screen_name_list, output_id, user_index, timelines)\n",
    "            # Reset Output File ID, Data, and Downloaded Users\n",
    "            del timelines, downloaded_screen_name_list\n",
    "            output_id = str(uuid.uuid4())\n",
    "            timelines = pd.DataFrame()\n",
    "            downloaded_screen_name_list = []\n",
    "    # Save the rest of the timelines\n",
    "    save_timelines(downloaded_screen_name_list, output_id, len(screen_name_list) - 1, timelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Li7FfTFkEbgg",
    "outputId": "ace215a8-fe71-4480-b057-b21622e986dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noorfatima9695 Twitter error response: status code = 401\n",
      "Process processed 100 timelines with latest output file: ./data/timelines/timelines-99-8e68f085-9682-4f2d-a7af-1b2c90e3b92f.pkl\n"
     ]
    }
   ],
   "source": [
    "download_timelines(api_dict, screen_name_list = followers_screen_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JsYF4Sf1Ebgi"
   },
   "source": [
    "#### Download social network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJzFdneZEbgi"
   },
   "source": [
    "One last Tweepy feature we cover in this tutorial is the possibility to download a list of Twitter accounts that are followed by a specific Twitter account. The function below takes as input:\n",
    "- `api_dict` the API credentials in a dictionary format\n",
    "- `screen_name_list` a list of user screen names.\n",
    "\n",
    "This function will download the list of usernames each user in the `screen_name_list` follows and return the results as a dictionary, with `screen_name` of users given as input as keys and, a list of the users they follow as value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F6pNa2HvEbgi",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_friends(api_dict, screen_name_list):\n",
    "    api = get_auth(api_dict)\n",
    "    friends_dict = dict()\n",
    "    for screen_name in screen_name_list:\n",
    "        friends_list = list()\n",
    "        try:\n",
    "            for friend_ids in tweepy.Cursor(api.friends_ids, screen_name=screen_name).pages():\n",
    "                friends_list.extend(friend_ids)\n",
    "            friends_name_list = [user.screen_name for user in api.lookup_users(user_ids=friends_list)]\n",
    "            friends_dict[screen_name] = friends_name_list\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "    return friends_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ChkS25yEbgi"
   },
   "source": [
    "Let's do an example with Joe Biden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WSFpcNjXEbgj"
   },
   "outputs": [],
   "source": [
    "friends_dict = get_friends(api_dict, ['JoeBiden'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51hvcuCkEbgk"
   },
   "source": [
    "Below, we can find the list of users Joe Biden follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cB9YLANmEbgk",
    "outputId": "5bd62a4f-0b7d-43a9-ed32-909f5051af67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************Twitter users Joe Biden follows:**************\n",
      "['POTUS', 'teachcardona', 'AliMayorkas', 'ABlinken', 'JanetYellen', 'neeratanden', 'XavierBecerra', 'mlfudge', 'DenisMcDonough', 'PeteButtigieg', 'DebHaalandNM', 'JenGranholm', 'Michael_S_Regan', 'SecDef', 'Mariska', 'BidenInaugural', 'WhiteHouse', 'BlueAmerica22', 'DouglasEmhoff', 'KamalaHarris', 'JoeForNV', 'JoeForSC', 'JoeForNH', 'JoeForIA', 'TeamJoe', 'De11eDonne', 'ladygaga', 'ItsOnUs', 'DrBiden', 'UDBidenInst', 'BidenCancer', 'PennBiden', 'ObamaFoundation', 'livelihood2017', 'bidenfoundation', 'timkaine', 'HillaryClinton', 'DrBiden44', 'ObamaWhiteHouse', 'WhiteHouse45', 'VP44', 'VP45', 'BeauBidenFdn', 'TheDemocrats', 'MichelleObama', 'BarackObama']\n"
     ]
    }
   ],
   "source": [
    "print('**************Twitter users Joe Biden follows:**************')\n",
    "print(friends_dict['JoeBiden'])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "1-download-from-twitter-api.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
