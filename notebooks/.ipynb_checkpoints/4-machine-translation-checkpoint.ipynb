{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook #4: machine translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will show you how to translate text from one language to another in a few lines of code. We will use the `transformers` package from Hugging Face and load translation models trained by the Language Technology Research Group at the University of Helsinki (Helsinki-NLP)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "from transformers.hf_api import HfApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.4.0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this notebook, we are using the `3.4.0` version of the `transformers` package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below allows you to make use of the 1008 machine translation models covering 140 languages that Helsinki-NLP contributed to the Hugging Face model hub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Translator` class takes two languages as input: the source language `src_language` which is the language of the source input and the target language `tgt_language`. \n",
    "\n",
    "It has two important methods:\n",
    "- `load_model`: this method allows to load the model you want to use\n",
    "- `translate`: this method uses the `loaded_model` to translate the `src_text` you gave as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translator:\n",
    "    \n",
    "    model_list = HfApi().model_list()\n",
    "    valid_model_names = [x.modelId for x in model_list if x.modelId.startswith(\"Helsinki-NLP\")]\n",
    "    \n",
    "    def __init__(self, src_language, tgt_language):\n",
    "        self.src_language = src_language\n",
    "        self.tgt_language = tgt_language\n",
    "        self.model_name = f'Helsinki-NLP/opus-mt-{src_language}-{tgt_language}'\n",
    "        if self.model_name not in self.valid_model_names:\n",
    "            raise KeyError(f'{self.model_name} is not a valid model name.')\n",
    "\n",
    "    def load_model(self):\n",
    "        \"\"\"Load translation model and tokenizer.\"\"\"\n",
    "        tokenizer = MarianTokenizer.from_pretrained(self.model_name)\n",
    "        model = MarianMTModel.from_pretrained(self.model_name)\n",
    "        return tokenizer, model\n",
    "    \n",
    "    def translate(self, src_text, loaded_model):\n",
    "        \"\"\"Use loaded model and tokenizer to translate the source text.\"\"\"\n",
    "        tokenizer, model = loaded_model\n",
    "        translated = model.generate(**tokenizer.prepare_seq2seq_batch([src_text], return_tensors=\"pt\"))\n",
    "        return [tokenizer.decode(t, skip_special_tokens=True) for t in translated][0] \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first instantiate the `Translator` class using as example English as the source language and French as the target language. \n",
    "\n",
    "Languages are defined by their ISO 639-1 codes (you can find a list of these codes for each language [here](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes)). Not all language combinations are available: please check the [model list](https://huggingface.co/Helsinki-NLP) from `Helsinki-NLP` to see if the combination you're interested in is available. The model names are defined as follows: `Helsinki-NLP/opus-mt-<ISO_CODE_SRC_LANG>-<ISO_CODE_TGT_LANG>`. For instance, to check whether translation from English (ISO 639_1 = `en`) to French ( ISO 639_1 = `fr`), look for `Helsinki-NLP/opus-mt-en-fr`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17 µs, sys: 10 µs, total: 27 µs\n",
      "Wall time: 31.5 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "translator = Translator(src_language='en', tgt_language='fr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After instantiating the `Translator` class, we load the translation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d962d4b240ad4f9e952ef425a283fb2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=778395.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "942457fa4bf04c5fadb5a7799a264f67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=802397.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0999bb4a74b848fdb2656e3e4b65ee36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1339166.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cbf7ddb6ce9429aa27533e1800c559b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=42.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5380fbf10d04f0a91ab7e4a98c67326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1133.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a32de6e6d1343eea27fa981df334a96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=300827685.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = translator.load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we use the loaded model to translate the source text (`src_text` argument) in string format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.26 s, sys: 8.91 ms, total: 9.27 s\n",
      "Wall time: 2.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Bonjour, je voulais juste faire un test pour voir si cet outil de traduction fonctionne correctement.'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "translator.translate(\n",
    "    src_text='Hello, I just wanted to do a test to see if this translation tool is working properly. ',\n",
    "    loaded_model=model\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
